/*
Navicat MySQL Data Transfer

Source Server         : localhost
Source Server Version : 50521
Source Host           : localhost:3306
Source Database       : work

Target Server Type    : MYSQL
Target Server Version : 50521
File Encoding         : 65001

Date: 2017-04-28 18:04:32
*/

SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for knowledge
-- ----------------------------
DROP TABLE IF EXISTS `knowledge`;
CREATE TABLE `knowledge` (
  `id` int(20) NOT NULL AUTO_INCREMENT,
  `type` varchar(20) NOT NULL,
  `title` varchar(100) NOT NULL,
  `content` text,
  `link` varchar(200) NOT NULL,
  `createDate` datetime NOT NULL,
  `updateDate` datetime DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of knowledge
-- ----------------------------

-- ----------------------------
-- Table structure for users
-- ----------------------------
DROP TABLE IF EXISTS `users`;
CREATE TABLE `users` (
  `USER_ID` int(11) NOT NULL AUTO_INCREMENT,
  `USER_NAME` char(30) NOT NULL,
  `USER_PASSWORD` char(30) NOT NULL,
  `USER_PHONE` char(20) DEFAULT NULL,
  `USER_EMAIL` char(30) DEFAULT NULL,
  PRIMARY KEY (`USER_ID`),
  KEY `IDX_NAME` (`USER_NAME`)
) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of users
-- ----------------------------
INSERT INTO `users` VALUES ('1', '林炳文', '1234567@', '18069773749', 'ling20081005@126.com');
INSERT INTO `users` VALUES ('2', 'evan', '123', '18069773749', 'fff@126.com');
INSERT INTO `users` VALUES ('3', 'kaka', 'kaka', '18069773749', 'fwsfg@126.com');
INSERT INTO `users` VALUES ('4', 'simle', 'cscs', '18069773749', 'fsaf@126.com');
INSERT INTO `users` VALUES ('5', 'arthur', 'csas', '18069773749', 'fsaff@126.com');
INSERT INTO `users` VALUES ('6', '小德', 'yuh78', '18069773749', 'fdfas@126.com');
INSERT INTO `users` VALUES ('7', '小小', 'cvff', '18069773749', 'fsaf@126.com');
INSERT INTO `users` VALUES ('8', '林林之家', 'gvv', '18069773749', 'lin@126.com');
INSERT INTO `users` VALUES ('9', '林炳文Evankaka', 'dfsc', null, 'ling2008@126.com');
INSERT INTO `users` VALUES ('10', 'apple', 'uih6', null, 'ff@qq.com');
INSERT INTO `users` VALUES ('11', 'lwx355499', 'xuexun9842', '13735800275', 'lidiliang@qq.com');

-- ----------------------------
-- Table structure for work
-- ----------------------------
DROP TABLE IF EXISTS `work`;
CREATE TABLE `work` (
  `id` int(20) NOT NULL AUTO_INCREMENT,
  `workDate` date DEFAULT '2017-03-13',
  `workContent` text NOT NULL,
  `workStatus` text NOT NULL,
  `nextPlan` text NOT NULL,
  `conclusion` text NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=51 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of work
-- ----------------------------
INSERT INTO `work` VALUES ('1', '2017-01-03', '1,C30 中所有编译环境的jdk 和mvn统一<br />2,C30-2.0公共环境磁盘满了，需清理。（挂载磁盘，以及移动共用目录）', '0', '性能自动化CI计划对齐。', '1,接到的任务，性能自动化CI 搭建，没能及时地对齐。');
INSERT INTO `work` VALUES ('2', '2017-01-04', '1,C30 中，性能自动化CI目标对齐，环境部署。<br />', '0', '性能自动化CI的git库地址，编译分发脚本落实。\', \'1,该如何提高自己的效率\'', '');
INSERT INTO `work` VALUES ('3', '2017-01-05', '1,CI 中机器的整理。现在整理出来的机器，空闲的有51台。一个是6+1的，一个是之前15个子工程的。<br />2：给王如慧那边搭建一个测试的跑UT 的工程。', '0', '', '1,why you can not stay calm to read somethig.');
INSERT INTO `work` VALUES ('4', '2017-01-06', '1,tomcat 性能优化，参考着一些博客，进行配置。<br />', '0', '', '1，无日报总结，每天花个10分钟进行总结。');
INSERT INTO `work` VALUES ('5', '2017-01-09', '1,CI 机器的整理。整理出的机器，6+1工程，用到的机器有110台，剩余机器74台，C301.5机器45台，则，后面干掉C301.5基线的工程的话，有119台，刚好可以搭建另一套的工程。<br />2，6+1 工程问题梳理。', '0', '1，版本构建和MR 构建冲突方案。：2，工程对接看板。：3，6+1 Carbon 编译所处位置有误。需整改。', '1，无日报总结，每天花个10分钟进行总结。');
INSERT INTO `work` VALUES ('6', '2017-01-10', '1,版本构建和MR 工程共用机器，相互影响问题，方案已经有。<br />2,Carbon 6+1 工程中所处的位置的整改，完成。', '0', '', '');
INSERT INTO `work` VALUES ('7', '2017-01-11', '1,Hive_ODBC 工程，window 机器编译时，用mvn 编译zkcode 的时候报错，报错的是跑zkcode 的test 的时候。 网上说的是内存不足，以及某些jar 包调用了System.exit(). 参照着网上说的进行了修改，但是解决不了问题。<br />', '0', '', '');
INSERT INTO `work` VALUES ('8', '2017-01-12', '1,6+1 工程中，针对随机失败的SparkUT，可以尝试，重跑失败的UT，以及没跑的UT，方案正在整理中。', '0', '', '');
INSERT INTO `work` VALUES ('9', '2017-01-13', '1,杜军令的提的MR，工程提示编译错误，韩献的提MR工程会卡着。 分析了一下，没有找到原因.。<br/>2,与姜松对齐CI 性能测试的流层。现在编译已近可以跑通，后面需要把tar 包分发到各个测试的机器上。跑测试，然后把测试结果返回jenkins。<br /> 3,c20 Ci UT的streaming ut，失败，环境问题引起两次，随机失败一次，环境问题是，jenkins 清理工作目录的插件bug 没能清理本地的文件，导致构建失败。已经解决。<br /> 4,给2.0基线的mr工程添加机器，5台，正在测试中。<br />5，给李凯填请假的电子流。<br />', '0', '', '');
INSERT INTO `work` VALUES ('10', '2017-01-16', '1,CI周报整理。<br/>2,给2.0MR 添加5台机器，让MR 可以并行跑10个工程。<br/> 3,给erlu搭建一个临时的MR 工程。4，Fiber 的静态检查项，FindBug以及checkstyle 集成到工程中。', '0', '1，HiveOdbc windows 编译机器搭建.<br/>2,大集群性能测试CI。<b/>3,6+1 进展跟踪，两个问题，一个MR与版本UT 冲突，一个信息返回。<br/>4，TR5-2CI 环境准备。', '');
INSERT INTO `work` VALUES ('11', '2017-01-17', '1,HiveODBC windows 编译环境准备<br/> 2, 2.0 的UT 拆分改怎么拆，一个，先把所有的测试类找出来，拆分，按照涂铭给的jar 包，先拆分成85份左右。之后则是准备环境。', '0', '', '1,早上花个10分钟左右想想今天干什么。2，多问自己几个为什么。');
INSERT INTO `work` VALUES ('12', '2017-01-18', '1,2.0工程的总工程的调试，现在整个工程已经调通，Spark ut 还差41个自工程，等机器下来之后，就可以搭建好：2，总工程流程框架的整理，', '0', '', '1,懒惰，早起早睡是个好习惯');
INSERT INTO `work` VALUES ('13', '2017-04-01', '1，SPC100 Spark 版本构建周报整理，下午5点前整理好。\n2，SPC100 Spark 版本库打Tag，Tag 名字，DataSight_V100R002C50RC1B070,今天完成。\n3，生成C30SPC100 Spark 2.1  和C30SPC100 Spark 1.5 API DOCS。下午3点前完成。\n4，C30SPC100 Spark 1.5 的冒烟和全量，需要从Spark 代码库里面拉取用例。工程流程需要调整。\n5，C30SPC100 CI 日常维护。', '1，任务1，完成。\n2，任务2，完成。\n3，任务3，完成。\n4，任务4，现在集群已经可以启动成功，但是，跑用例的时候，会报找不到类，徐超超在看。\n5，CI 日常维护：1，修复CI 构建中，Spark 2.x 全量测试工程失败的问题。失败原因，冒烟和全量工程跑在同一天机器上，共同操作同一份本地的maven jar 包导致。后续操作，让全量和冒烟错看两分钟来构建。并且，在冒烟跑完后，把本地的maven jar 包给删除掉。 2，后续的CI 重跑机制测试，可以在groovy 脚本里面，定义retry  让工程重跑随机失败的工程。如果工程失败，那么重跑一次，两次都失败，才认为是失败。\n', '1，跟踪bazel 跑Spark UT 工程的情况。\n2，继续整理Spark 版本构建剩下的东西，整理成文档。\n3，CI 重跑随机失败工程机制对齐。\n4，Spark MR 跑CI 的时候，可以触发冒烟工程，是否加到MR 里。', 'NA');
INSERT INTO `work` VALUES ('14', '2017-04-05', '1，整理Spark 版本构建的流程，svn，git 库信息：整理成文档。（预计需要两天。）\n2，继续跟踪对齐冒烟测试工程跑所有用例时的情况。（今天完成）\n3，对齐C30SPC100 Spark 1.5 跑冒烟和全量的工程，需要从开发的代码库把用例拉取下来，而不是从测试的主库上获取用例。（需要两天）\n4，CI 日常维护。\n', '1，整理了50% 的文档，文档整理后需要修改，方便后续维护。\n2，冒烟工程，后续如果需要指定跑哪些用例，可以把用例写在一个文件里面。以用例类：具体用例的格式保存。\n3，现在Spark 冒烟的工程已经搭建，从spark 开发库上拉取代码，还需要调试。\n4，CI 维护： 一，旧版本C30 LLT 失败，失败原因，因为JVM 异常引起的随机失败，解决办法暂时没有。日记文件已经保存。\n二，修改收集版本构建状态信息的工程，替换成最新的jar 包，方便CI 看板收集数据。同时整理Spark 版本子工程情况。\n', '1，发布版本V100R002C50RC1B060 ，版本包。\n2，冒烟工程从C30SPC100 spark 1.5冒烟工程需要从spark 主库拉取代码。\n3，整理SPC100 spark 工程构建流程。', '冒烟工程从C30SPC100 spark 1.5冒烟工程需要从spark 主库拉取代码。这个任务有风险，1，没有熟悉冒烟的整体流程。2，工程急需用到版本构建里面。');
INSERT INTO `work` VALUES ('15', '2017-04-06', '1，调试SPC100 Spark 2.x冒烟工程，让冒烟工程可以指定跑指定的某些测试用例。（预计今天调试完成。）\n2，完成修改C30SPC100 spark 2.x 生成的tar 包的脚本，spark tar 包里需要包含scopt_2.11_3.3.0.jar和spark-examples_2.11-2.1.0.ja， 不可以包含original-spark-examples_2.11-2.1.0.jar ，此修改是为了修复spark 自带样例执行失败的问题。（今天完成。）\n3，完成C30SPC100 中，Spark 1.5 和Spark 2.x MR 工程，需要把打包的spark tar 包，tar 包名中的版本号自动同步到当前版本号的操作。（今天完成。）\n4，C30SPC100 Spark 版本构建维护。\n', '1，任务一，已经完成调试冒烟工程，但是，测试调度框架存在Bug，无法指定一个类里面的所有用例。\n2，任务二，打包Spark 2.x 的tar 包的脚本已经修改完成。并且同步到svn 中。\n3，已经完成，把当前版本号以文件的形式存到svn 即可，然后MR 跑的时候从svn 获取版本号文件。\n4，日常维护：一，刷新spark 2.x 代码库，git@code.huawei.com:datasight/Spark_2.x_V1R2C30.git 中DataSight_V100R002C50RC1B060 的tag ，原因Spark 刷包。二，spark 1.5 中hbase 有三个testcase 用例失败，已经联系徐超超在分析修复。三，帮赖玲替换jenkins.jar 这个jar 包，用来收集版本构建的信息。四，协助王磊、秦泽会、武家琦搭建调试测试工程。 ', '1，整理Spark 版本构建的流程，svn，git 库信息：整理成文档。\n2，继续跟踪冒烟测试工程跑所有用例时的情况。\n3，对齐后续MR 工程触发时，触发冒烟测试的事情，因为现在工程还在调试阶段。', 'NA');
INSERT INTO `work` VALUES ('16', '2017-04-07', '1，删除SPC100 Spark 2.x 上没用的工程。（预期4月18号完成。)\n2，搭建冒烟工程，测试SPC100 Spark 2.x冒烟工程新的跑用例的范式。（预计明天完成工程搭建。）\n3，协助余坚峰，搭建bazel 编译Spark 代码的工程，以及搭建跑SPC100 Spark 1.5 ut 的环境。\n4，给Spark 的6个代码库，和3个样例代码库打Tag。方便回溯。\n5，对齐Spark 2.x 中的platform.tar.gz 中为何会少很多hadoop 的jar 包。预计晚上7点左右可以定位出原因，并向唱娟对齐。\n6，CI 日常维护。', '1，任务1，已经把SPC100 Spark2.x 工程上的无用的工程给删除掉。\n2，任务2，预计晚上9点左右，可以使工程构建起来。\n3，任务3，bazel 编译spark 代码工程概念已经完成，spc100 spark 1.5 ut 环境已经搭建好，给余坚峰做测试用。\n4，一共9个代码库打tag 已经完成，Tag 名称。DataSight_V100R002C50RC1B060，\n5，对齐Spark 2.x 中的platform.tar.gz 中为何会少很多hadoop 的jar 包。预计晚上7点左右可以定位出原因，并向唱娟对齐。\n6，CI 维护： 一：修复C00 Spark CI LLT-Security 工程失败，环境引起的问题，由于krb5kdc 和kadmind服务没有启动导致。直接执行命令：kadmind  和   krb5kdc 进行解决。\n', '1，调试SPC100 Spark 2.x冒烟工程，让冒烟工程可以指定跑指定的某些测试用例。（预计明天可以把工程概念调通）\n2，向黄球请教，单元测试ut 改如何实现重跑机制。（预计明天对齐方案。）', 'NA');
INSERT INTO `work` VALUES ('17', '2017-04-10', '1，继续整理好上周版本构建的构建情况，下午5:30前发给郭云静。（预计4月17号完成。）\n2，删除SPC100 Spark 2.x 上没用的工程。（预计4月17号完成。）\n3, V100R002C30SPC100B060 版本包发布，（修改版本号，处理好环境引起的问题，）\n4，C30SPC100 CI 版本日常维护。', '1，继续整理好上周版本构建的构建情况，下午5:30前发给郭云静。（DONE）\n2，删除SPC100 Spark 2.x 上没用的工程。（延期到4月17号，今天跟踪分析处理冒烟和全量失败占的时间比较长。）\n3，V100R002C30SPC100B060 版本包发布，今天晚上10点左右发布。\n4，CI 日常维护：一，C30 Spark 2.x  冒烟和全量 测试，修复环境引起的问题一个。二，C30 Spark 2.x 一个旧特性用例，陈金生在看。', '1，删除SPC100 Spark 2.x 上没用的工程。（预期4月18号完成。）\n2，搭建冒烟工程，测试冒烟工程新的跑用例的范式。（预计明天完成工程搭建。）\n', 'NA');
INSERT INTO `work` VALUES ('18', '2017-04-11', '1，完成SPC100 Spark 2.1 工程改名的所有内容。改成名字类似V100R002C30SPC100字样，为了区分旧版本的V100R002C30\n2，C30SPC100 Spark 两个版本（Spark 1.5 和Spark 2.1）的CI 周报整理。大概需要6个小时。可以分两次完成，周五先完成一半。\n3， C30SPC100 Spark CI 日常维护。（优先处理环境引起的问题。）', '1, Spark 版本工程名改名，done。\n2,V100R002C30SPC100  Spark 两个版本的周构建情况总结，完成50%。\n3，C30SPC100 Spark CI 日常维护。一，清理SPC100 Spark 两个版本改名后，遗留在slaves 机器上的残留文件。防止磁盘空间晒满。二，整理SPC100 Spark 1.5 版本构建的整个流程文档。三，中午的版本构建，冒烟工程编译失败，是因为开发合入的代码导致。已经联系开发修复。四，有一个工程，jenkins 用户删除jenkins 用户的文件的时候，会删除不了文件，现在规避的办法是，切换成jenkins 用户，把文件给删除掉。类似如下：echo \"huawei\" | su root -C \"rm -rf  hello\"', '1，继续整理好上周版本构建的构建情况，下午5:30前发给郭云静。（预计4月17号完成。）\n2，删除SPC100 Spark 2.x 上没用的工程。（预计4月17号完成。）', 'NA');
INSERT INTO `work` VALUES ('19', '2017-04-12', '1，SPC100 Spark 1.5 工程改名闭环， SPC100 Spark 2.1 工程概名完成90% 以上。改成名字类似V100R002C30SPC100字样，为了区分旧版本的V100R002C30\n2，搭建冒烟工程，测试新的跑冒烟的形式。\n3，推动何召磊完成Spark 1.5 组件分离的冒烟和全量工程的调试。\n4，SPC100 Spark CI 日常维护。', '1， SPC100Spark 1.5工程已经完成，SPC100Spark 2.1 工程，今天要合的代码比较多，今天晚上大概可以完成80%，预计明天可以闭环。（4月14号闭环）\n2，冒烟工程还没有搭建，这个工程，有限级别不高，可以放到4月18号搭建。（暂时关闭。）\n3，何召磊的spark 1.5 组件分离的冒烟和全量工程搭建和适配，后续教导郭云静和徐超超手上，（闭环）\n4，SPC100 Spark CI 日常维护，一，SPC100 Spark 2.1 的全量功能用例，有共21个用例是失败的。 其中一个是因为代码引起的。其余20个是因为环境因素引起的，具体的根因还没有找到。二，方丰斌看的一个Spark 2.x 的随机失败用例，org.apache.spark.streaming.ReceiverSuite.receiver life cycle已经可以闭环。\n\n', '1，完成SPC100 Spark 2.1 工程改名的所有内容。改成名字类似V100R002C30SPC100字样，为了区分旧版本的V100R002C30\n2，C30SPC100 Spark 两个版本（Spark 1.5 和Spark 2.1）的CI 周报整理。大概需要6个小时。可以分两次完成，周五先完成一半。\n3， C30SPC100 Spark CI 日常维护。', 'NA');
INSERT INTO `work` VALUES ('20', '2017-04-13', '1，继续完成 SPC100 ,Spark 1.5 和Spark 2.1 工程的改名，完成版本的初步调试。\n2，对齐后续SPC100 Spark冒烟工程的跑用例的方式。\n3，跟踪Spark 1.5 组件分离中的Spark 冒烟和 全量工程的完成情况。\n4，CI日常维护。', '1，版本工程改名，Sprak 1.5 完成90%，Spark2.1 完成60%,\n2，任务2，后续SPC100 Spark冒烟工程的跑用例的方式。已经对齐，后续可以把用例直接存在本地的一个文件中，用例以规定的格式存放。\n3，Spark 1.5 组件分离的冒烟和全量工程，Spark 冒烟已经完成90%， Spark 全量还没有调试好。\n4，日常维护：1，统计Spark 1.5 和 Spark 2.1 6个代码库的从1月9号到现在的代码量的统计。2，推进开发和测试分析spark 2.1 的一个旧特性用例。目前测试和开发还没有分析出原因。3，协助黄葳完成spark 代码的黑鸭扫描。', '1，Spark 1.5 工程改名闭环， Spark 2.1 工程概名完成90% 以上。\n2，搭建冒烟工程，测试新的跑冒烟的形式。\n3，推动何召磊完成Spark 1.5 组件分离的冒烟和全量工程的调试。', 'NA');
INSERT INTO `work` VALUES ('21', '2017-04-14', '1，C50 FI 包，对应版本V100R002C30SPC100b050拷贝到存包机器。\n2，C30SPC100 Spark 1.5 和Spark 2.1 工程名改名，改成类似V100R002C30SPC100， 为了区分原来的旧版本的工程。\n3，C30SPC100--Spark1.5 冒烟和全量完成调试。\n4，和俞珏琛对齐后续C30SPC100 Spark冒烟指定冒烟跑指定用例的方式。\n5，完成两个Spark 版本 API 文档，对应着C30 SPC 100 Spark 2.1 和Spark 1.2 的API docs 文档的交付。\n6，Spark 工程日常维护。', '1，C50 FI 包拷贝到存包机器（DONE）\n2，工程改名，Spark 1.5 和 Spark 2.1 ，都分别完成了5分之3 的工程名字改名。后续需要对版本工程进行调试，调试好后，正式放到版本构建中启用。\n4，暂无进展。\n5，晚上之9点前，把API 文档发给王南竹。\n6，Spark 工程日常维护：：一，修复C30SPC001 中LLT 集群因为放假期间，机器重启导致集群时间不同步问题。二，协助开发和测试，给开发和测试提供随机失败日记存放位置。', '1，继续完成 Spark 1.5 和Spark 2.1 工程的改名，完成版本的初步调试。\n2，对齐后续冒烟工程的跑用例的方式。\n3，跟踪Spark 1.5 组件分离中的Spark 冒烟和 全量工程的完成情况。', '1，Spark 1.5 和Spark 2.1 工程的改名，可能对MR 工程有应影响，会影响到开发提MR 工程。\n');
INSERT INTO `work` VALUES ('22', '2017-04-17', '1，规划Spark 1.5 工程和spark 2.1 工程里，冒烟工程和全量工程改如何构建。是否加到版本里面。冒烟需要加到版本里，全量的只需要定时构建。另外Spark 1.5 的冒烟和全量没有调通。\n2，sbt 版本升级，用于构建spark 的代码。先把工程给搭间起来。\n3，着手开始修改spark 1.5 的工程的工程名。（预计需要两天，计划4月10号和11号完成。）\n4，CI 周报整理，（需要3到4个小时。）\n5，对齐任务，给印度出补丁包,和全量包。\n6，和王建超对齐后续冒烟指定冒烟跑指定用例的方式。', '1，任务1，完成。\n2，任务2，无进展，不是紧急任务，先进行挂起。\n3，任务3，无进展。\n4，任务4，完成CI 周报整理。\n5，任务5，完成。\n6，任务6，还需要和俞珏琛 对齐。', '1，C50 FI 包拷贝到存包机器。\n2，工程名改名。\n3，C30SPC100--Spark 冒烟和全量完成调试。\n4，和俞珏琛对齐后续冒烟指定冒烟跑指定用例的方式。', '1，C30SPC100--Spark 冒烟和全量完成调试，需要和何召磊对齐，工程我这边不会调试，何召磊那边可能没办法及时完成。');
INSERT INTO `work` VALUES ('23', '2017-04-18', '任务1，已经对其后续版本发布邮件的事情，后续版本发布，统一由我这边出口，发版本前，FI 基线等事情先和尹旺对齐。（done）\n任务2，环境已经部署，具体需要学习sbt 构建，看sbt 构建原理和流程。\n任务3，工程名修改，工作量大，如果直接修改，可能会对版本构建有影响。所以，采取的办法是，每个工程拷贝一份，先进行调试，调试好后，把旧版本的给删除掉。\n任务4，CI 日常维护，主要内容，一，基于V100R002C30SPC100B030 出一个补丁包；二，对齐Spark 1.5 工程上，冒烟工程和全量工程改如何构建。是否加到版本里面。三，CI 每日构建整理。四，spark 2.x 11个功能用例失败跟踪，carbon2.1 ,2个ut 用例失败，spark 1.5 上面，一个hadoop 的用例失败，联系责任人，为他们提供错误日记目录。确认分析进展。', '任务1，已经对其后续版本发布邮件的事情，后续版本发布，统一由我这边出口，发版本前，FI 基线等事情先和尹旺对齐。（done）\n任务2，环境已经部署，具体需要学习sbt 构建，看sbt 构建原理和流程。\n任务3，工程名修改，工作量大，如果直接修改，可能会对版本构建有影响。所以，采取的办法是，每个工程拷贝一份，先进行调试，调试好后，把旧版本的给删除掉。\n任务4，CI 日常维护，主要内容，一，基于V100R002C30SPC100B030 出一个补丁包；二，对齐Spark 1.5 工程上，冒烟工程和全量工程改如何构建。是否加到版本里面。三，CI 每日构建整理。四，spark 2.x 11个功能用例失败跟踪，carbon2.1 ,2个ut 用例失败，spark 1.5 上面，一个hadoop 的用例失败，联系责任人，为他们提供错误日记目录。确认分析进展。', '1，规划Spark 1.5 工程和spark 2.1 工程里，冒烟工程和全量工程改如何构建。是否加到版本里面。冒烟需要加到版本里，全量的只需要定时构建。另外Spark 1.5 的冒烟和全量没有调通。\n2，sbt 版本升级，用于构建spark 的代码。先把工程给搭间起来。\n3，着手开始修改spark 1.5 的工程的工程名。（预计需要两天，计划4月10号和11号完成。）\n4，CI 周报整理，（需要3到4个小时。）', '1，升级sbt 版本工具来编译spark 代码，有风险，因为对sbt 的构建过程和原理不够了解。\n2，修改工程名有风险，总共300 多个工程，都需要一个一个人为修改，修改可能对现有工程有影响，而且需要把整个修改后的工程调试通。');
INSERT INTO `work` VALUES ('24', '2017-04-20', '1，发布V100R002C30SPC100B050 版本。（计划今天4月6号完成）\n2，跟踪闭环版本构建中ut 随机失败的问题。（计划今天4月6号闭环C30SPC100 中hbase 的随机失败问题。其他未找到根因的，需要向PM提出。）\n3, 对齐C30SPC100 Spark 1.5 和 Spark 2.1 构建情况，刷新整理的构建情况表格给赵琪。（计划今天4月6号完成）\n4，协助开发，解决如果同一个MR 提交两次，第二次提交的内容无法触发的情况。（计划今天4月6号完成）\n5，出临时补丁包，给开发验证补丁工具是否可用。（计划今天4月6号完成）\n6，收集V100R002C30SPC100B050 编译所需要的第三方jar包。\n7，给Spark 的库打tag。', '1，发布V100R002C30SPC100B050 版本done。\n2，随机失败UT 的闭环（SPC100 Spark 1.5 hbase 中的随机失败UT，剩下SPC100Spark 2.1的随机失败问题。）\n3，计划3，done，\n4，计划4，done，解决办法，先修改第二次的MR，可以任意改内容，然后改回来，\n5，任务5，done,补丁包已经发给开发。\n6，任务6，done。\n7，任务7，done。\n（今日所计划事情done）', '1，与尹旺对齐后续发布包的发邮件的事情。（预计明天完成。）\n2，搭建工程，尝试搭建工程，升级sbt 编译的版本，用来编译spark（预计下周一完成，4月10号）\n3，规划工程名改名的事情，改名改怎么改，怎么才可以更下快速，而且对哪些工程有影响，罗列计划（明天完成。）', 'NA');
INSERT INTO `work` VALUES ('25', '2017-04-21', '1，完成spc100 每次正式发版本的时候，都把编译spark1.5，fiber，odbc ，carbon1.5,spark 2.1 ,carbon 2.1 所依赖的jar 包收集好。（计划今天4月5号完成）\n2， 版本整改，完成版本构建的流程的整改，细化到每个子工程，而不是把一个总工程添加到版本构建里。（计划今天4月5号完成）\n3，每天版本构建后，关于收集数据的工程，spark 的总工程和hadoop 总工程的build.xml 不一致的解决办法。（计划今天4月5号完成）\n4，出一个临时的包，给spark 验证补丁工具的可用性。 （计划今天4月5号完成）\n5，版本周构建的整理。（计划今天4月5号完成）', '计划1，收集jar 包的工程已经建好，可以闭环。（done）\n计划2，版本整改已经整改好，已近加到版本构建里，可以闭环。（done）\n计划3，收集版本构建情况的工程已近调通，可以收集到数据了，可以闭环。（done）\n计划4，给补丁工具，出一个临时的补丁包，和全量包，，验证补丁工具是否可用。已经完成，可以闭环。（done）\n计划5，版本周构建整理，已经完成。（done）', '1，发布V100R002C30SPC100B050 版本。（计划明天完成）\n2，跟踪闭环版本构建中ut 随机失败的问题。（计划明天闭环SPC001 中hbase 的随机失败问题。其他未找到根因的，需要向PM提出。）', '1，随机失败的UT 中，有9个随机失败的是没有找到跟因的。需要想PM 反馈。');
INSERT INTO `work` VALUES ('26', '2017-04-24', '1，搭建工程，每次版本发布完成后，收集SPC 100 两个版本，spark 1.5 和spark 2.1 中，编译spark 1.5 ，spark2.1，fiber ， odbc ，carbon 1.5 ，carbon2.1 所依赖的第三方jar。\n2，跟踪SPC100 两个版本的CI 构建随性失败，协助开发分析问题。\n3，搭建每次版本构建跑完后，收集版本构建信息的工程。\n4，版本构建整个流程重新架构。\n5，CI 日报整理。', '1，对应的第一个任务，还有carbon2.1 和spark2.1 的jar 包收集。\n2，随机失败，问题已经初步分析，\n3，收集版本构建的工程，工程已经搭好，可以跑通，但是收集不到数据。\n4，框架已经重构，可以跑通，待稳定后加到版本构建中。\n5，CI 日报整理已发邮件。', '1，完成carbon2.1 和spark2.1 的jar 包收集。\n2，随机问题继续跟踪闭环。\n3，需要与lailing和黄球进行沟通，为何收集不到版本构建的数据。', '无');
INSERT INTO `work` VALUES ('27', '2017-04-26', '1，编写和整理C50 Spark 1.5 和 2.x 版本编译的编译指导书。（计划今天完成。）\r\n2，C30SPC100 Spark 1.5 冒烟和全量工程，需要从开发的spark 代码库拉取测试用例。（计划周五4月28号前完成）\r\n3，C30SPC100 Spark 2.1 的platForm.tar.gz 中少了一个zookeeper-3.5.1.jar 的jar 包。需要修改脚本，在打包的时候加上。（计划今天完成。）\r\n4，基于V100R002C30SPC100B030_201703241816 这个基线的包，用现在V100R002C50RC1 最新的包做一个临时的补丁包。 （计划今天完成。）\r\n5，修复C30SPC100 Spark 1.5 中收集spark jar 包工程的失败。（计划上午完成）\r\n6，任务六。HQ 全量用例跟踪失败修复情况，一个spark 用例随机失败。', '1，任务一，两个编译指导书已近发给叶梅。\r\n2，任务二，现在集群已经可以启动成功，但是徐超超那边还有一些必须的内容没有合到Spark 的代码库里面。需要等这个版本VT  完，然后代码才可以合。\r\n3，任务三，少了的zookeeper-3.5.1.jar 已经加到paltform.tar.gz 这个tar 包中。\r\n4，任务四，临时补丁包已经完成。\r\n5，任务五，已经修复。工程失败原因，svn 迁移到新的库后，下载svn脚本的工程，没有相应的的修改。而且收集jar 包工程，脚本没有每次清空，昨天加了清空操作后，今天报找不到脚本文件的错误。\r\n6，任务六，定位到原因，JVM Crash 导致用例失败。', '1，C30SPC100 Spark 1.5 工程名改名。', 'NA');
INSERT INTO `work` VALUES ('28', '2017-04-27', '1，C30SPC100 Spark 1.5 工程名改名。（工作量比较大，对版本有影响，涉及改动比较多，需要两天左右时间。）\r\n2，和徐超超，方丰斌对齐Spark Merge Request 工程跑时，把冒烟工程架包MR 中，冒烟工程改大概流程，开发如何在跑冒烟的同时，跑自己新增的测试用例对齐。\r\n3，编写C50 Spark 1.5 和2.1 编译指导书，目前已经完成，需要合并成一个文档，叶梅那边正在验证。 ', '1，C30SPC100 Spark 1.5 工程名改名。改名完成了80%。\r\n2，内容已经对齐，冒烟的整个大致流程，如何在跑冒烟的同时，跑开发自己新增的用例已经对齐，文档已经整理发给Spark 开发全组组员。\r\n3， 目前C50 Spark 2.1 和1.5 编译指导书已经发给叶梅，叶梅验证完后，会提出修改意见，之后会合并成同一个文档，现在正在合并文档。', '1，C30SPC100 Spark 1.5 工程名改名，闭环这个任务，并开始C30SPC100 Spark 2.1 工程改名。 ', '原本的工程改名计划时间需要延迟，延迟一天左右');
INSERT INTO `work` VALUES ('29', '2017-03-28', '1，C30SPC100 Spark 1.5 工程名改名，闭环这个任务，并开始C30SPC100 Spark 2.1 工程改名。\r\n2, C30SPC100 Spark 1.5  和Spark 2.1 编译指导书修改。\r\n3，日常维护跟踪。', '1，工作进展75%，C30SPC100 Spark 1.5 工程改名已经可以闭环。 现在在做的是给C30SPC100 Spark 2.1 工程改名， 考虑到后面可能还需要改名字，现在考虑到的是，把名字统一命名成V1R2C30SPC100_Spark2.x_*******, 后续改名的时候，统一改前面一段即可。\r\n2，C30SPC100 Spark 1.5  和Spark 2.1 编译指导书修改，根据叶梅的邮件，里面有四处左右需要修改的，已经完成修改，计划下周二完成交付。\r\n3，日常维护：\r\nspark 2.x 中有一个UT 随机失败，现在已经联系到开发进行分析。正在分析中，还没结论。', '1，C30SPC100 Spark 1.5 和Spark 2.1 周报整理。\r\n2，完成剩余的C30SPC100 Spark 2.1 的改名工作。\r\n3，清理改名后的机器的中残留的旧工程的文件。', 'NA');
